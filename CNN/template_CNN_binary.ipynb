{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Image - cats and dogs (from kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the folders with the images:\n",
    "\n",
    "# class folder\n",
    "train_cats_dir = 'data/training_set/cats'\n",
    "train_dogs_dir = 'data/training_set/dogs'\n",
    "\n",
    "validation_cats_dir = 'data/validation_dir/cats'\n",
    "validation_dogs_dir = 'data/validation_dir/dogs'\n",
    "\n",
    "test_cats_dir = 'data/test_set/cats'\n",
    "test_dogs_dir = 'data/test_set/dogs'\n",
    "\n",
    "# main folders\n",
    "train_dir = 'data/training_set/'\n",
    "validation_dir = 'data/validation_dir'\n",
    "test_dir = 'data/test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "\n",
    "print ('total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "\n",
    "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
    "\n",
    "print ('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "\n",
    "print ('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
    "\n",
    "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
    "\n",
    "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "1) Read the picture files. <br>\n",
    "2) Decode the JPEG content to RGB grids of pixels. <br>\n",
    "3) Convert these into floating point tensors. <br>\n",
    "4) Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values). <br> <br>\n",
    "Keras has a module for image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale all images by 1/255\n",
    "# Train\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# Validation\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this generator will continuously create from this directory\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(150,150), #size of the final image\n",
    "                                                   batch_size=20, #will return batches of 20 images at each time\n",
    "                                                   class_mode='binary') #binary classification (if it was multiclass = categorical)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                       target_size=(150,150),\n",
    "                                                       batch_size=20,\n",
    "                                                       class_mode='binary',\n",
    "                                                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the data augmentation only for the training data\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this generator will continuously create from this directory\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(64,64), #size of the final image\n",
    "                                                   batch_size=1, #will return batches of 20 images at each time\n",
    "                                                   class_mode='binary') #binary classification (if it was multiclass = categorical)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=(64,64),\n",
    "                                                  batch_size=1,\n",
    "                                                  class_mode='binary',\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# Conv 1\n",
    "# size of the image 150x150 (3 RGB), 32 neurons, (3,3) strides \n",
    "model.add(layers.Conv2D(32,\n",
    "                         (3,3),\n",
    "                         activation='relu',\n",
    "                         input_shape=(150, 150, 3)))\n",
    "# MaxPooling 1\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "# Conv 2\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "# MaxPooling 2\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "# Conv 3\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "#  MaxPooling 3\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "# Conv 4\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "#  MaxPooling 4\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "# Fully connected NN\n",
    "model.add(layers.Flatten())\n",
    "# Dense Layer 1\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "# Output layer - sigmoid for binary and softmax for multiclass\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture of the NN\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Loss | Optimizer | Metrics\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['acc']) # for accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=100, #depends on the size of the batch and te total images for training (steps_per_epoch * batch_size = size of training set)\n",
    "                    epochs=30,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=50)  #depends on the size of the batch and te total images for validation (validation_steps * batch_size = size of validation set)\n",
    "\n",
    "# save the model\n",
    "model.save('cats_and_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of the metrics saved on history dictionary\n",
    "\n",
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap - class activation heatmap for an image classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Grad-CAM algorithm\n",
    "\n",
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to overlap the heatmap and the real image\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = keras.preprocessing.image.load_img(img_path)\n",
    "    img = keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test in one image prodiction - define the parameters:\n",
    "\n",
    "# name form model.summary() of the last CNN layer\n",
    "last_conv_layer_name = 'conv2d_1'\n",
    "\n",
    "# The local path to our target image\n",
    "img_path = 'data/test_set/dogs/dog.4010.jpg'\n",
    "\n",
    "# Size of the training\n",
    "img_size = (64,64)\n",
    "display(Image(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "\n",
    "# Prepare image\n",
    "img_array = get_img_array(img_path, size=img_size)\n",
    "\n",
    "# Make model\n",
    "# model = model_builder(weights=\"imagenet\")\n",
    "\n",
    "# Remove last layer's softmax\n",
    "model.layers[-1].activation = None\n",
    "\n",
    "# Print what the top predicted class is\n",
    "preds = model.predict(img_array)\n",
    "print(\"Predicted:\", np.argmax(preds[0]))\n",
    "\n",
    "# Generate class activation heatmap\n",
    "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap)\n",
    "plt.show()\n",
    "\n",
    "save_and_display_gradcam(img_path, heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3afd82841a532abc77895a6f97db9c967737f106822f294a6d88834b9baf47ca"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
